{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Found 6414 validated image filenames belonging to 7 classes.\n",
      "Found 1604 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from itertools import cycle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "import shutil\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Paths\n",
    "train_dir = r\"C:\\Users\\guitar123\\Desktop\\Senior Project\\dataset\\HAM10000 Original\\train\"\n",
    "val_dir = r\"C:\\Users\\guitar123\\Desktop\\Senior project\\dataset\\HAM10000\\val\"\n",
    "test_dir = r\"C:\\Users\\guitar123\\Desktop\\Senior project\\dataset\\HAM10000\\test\"\n",
    "\n",
    "# Constants\n",
    "IMAGE_HEIGHT = 600\n",
    "IMAGE_WIDTH = 450\n",
    "SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "IMAGE_CHANNELS = 3  # Assuming RGB images\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1000\n",
    "NUM_CLASSES = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load filenames and labels\n",
    "train_data = glob(os.path.join(train_dir, '*', '*.jpg'))  # List of image file paths\n",
    "train_labels = [path.split('\\\\')[-2] for path in train_data]  # Extract the class names from directory structure\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Set up 5-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Train on each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_data, train_labels_encoded)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    \n",
    "    # Split the data\n",
    "    train_data_fold = np.array(train_data)[train_idx]\n",
    "    val_data_fold = np.array(train_data)[val_idx]\n",
    "    train_labels_fold = train_labels_encoded[train_idx]\n",
    "    val_labels_fold = train_labels_encoded[val_idx]\n",
    "    \n",
    "    # Convert integer-encoded labels back to string labels\n",
    "    train_labels_fold_str = label_encoder.inverse_transform(train_labels_fold)\n",
    "    val_labels_fold_str = label_encoder.inverse_transform(val_labels_fold)\n",
    "    \n",
    "    # Set up ImageDataGenerator for this fold using string labels\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=pd.DataFrame({'filename': train_data_fold, 'class': train_labels_fold_str}),\n",
    "        directory=None,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=pd.DataFrame({'filename': val_data_fold, 'class': val_labels_fold_str}),\n",
    "        directory=None,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Load the InceptionResNetV2 model without the top fully connected layers (include_top=False)\n",
    "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n",
    "\n",
    "    # Freeze the base_model layers to prevent them from being trained\n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top of the base model without L2 regularization\n",
    "    x = base_model.output\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Add Dense layers without L2 regularization\n",
    "    #x = Dense(128, activation='relu')(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    #x = Flatten()(x)\n",
    "    #x = Dense(64, activation='relu')(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    #x = Dense(32, activation='relu')(x)\n",
    "\n",
    "    # Final output layer\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    # Define the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Reduce learning rate on plateau\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    # Metrics callback for precision\n",
    "    class MetricsCallback(Callback):\n",
    "        def __init__(self, val_generator):\n",
    "            super(MetricsCallback, self).__init__()\n",
    "            self.val_generator = val_generator\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            y_true = self.val_generator.classes\n",
    "            y_pred = self.model.predict(self.val_generator)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "            # Calculate precision only\n",
    "            precision, _, _, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "            val_loss = logs['val_loss']\n",
    "            val_accuracy = logs.get('val_accuracy', logs.get('val_acc'))  # Handle different versions\n",
    "\n",
    "            print(f'Epoch {epoch + 1} - '\n",
    "                  f'Validation Loss: {val_loss:.4f}, '\n",
    "                  f'Validation Accuracy: {val_accuracy:.4f}, '\n",
    "                  f'Validation Precision: {precision:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Model checkpoint\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'5foldInceptionResnetV2.h5',  # Save model for each fold\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model for this fold\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[early_stopping, MetricsCallback(val_generator), checkpoint, reduce_lr],\n",
    "        verbose=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from itertools import cycle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "import shutil\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('5foldInceptionResnetV2.h5')\n",
    "\n",
    "# Verify the model structure\n",
    "model.summary()\n",
    "\n",
    "# Paths\n",
    "train_dir = r\"C:\\Users\\guitar123\\Desktop\\Senior Project\\dataset\\HAM10000 Original\\train\"\n",
    "val_dir = r\"C:\\Users\\guitar123\\Desktop\\Senior project\\dataset\\HAM10000\\val\"\n",
    "test_dir = r\"C:\\Users\\guitar123\\Desktop\\Senior project\\dataset\\HAM10000\\test\"\n",
    "\n",
    "# Constants\n",
    "IMAGE_HEIGHT = 600\n",
    "IMAGE_WIDTH = 450\n",
    "SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "IMAGE_CHANNELS = 3  # Assuming RGB images\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate data from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Function to compute and print precision, recall, and F1-score for a dataset\n",
    "def compute_metrics(generator, generator_name):\n",
    "    # Get predictions\n",
    "    predictions = model.predict(generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Get true labels\n",
    "    true_classes = generator.classes\n",
    "    class_labels = list(generator.class_indices.keys())\n",
    "\n",
    "    # Compute precision, recall, f1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    # Print results\n",
    "    print(f'{generator_name} Precision: {precision:.4f}')\n",
    "    print(f'{generator_name} Recall: {recall:.4f}')\n",
    "    print(f'{generator_name} F1-Score: {f1:.4f}')\n",
    "    print()\n",
    "\n",
    "# Evaluate accuracy and compute precision, recall, F1 for train, val, and test data\n",
    "train_score = model.evaluate(train_generator)\n",
    "print('Train accuracy:', train_score[1])\n",
    "compute_metrics(train_generator, 'Training')\n",
    "\n",
    "val_score = model.evaluate(val_generator)\n",
    "print('Validation accuracy:', val_score[1])\n",
    "compute_metrics(val_generator, 'Validation')\n",
    "\n",
    "test_score = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_score[1])\n",
    "compute_metrics(test_generator, 'Test')\n",
    "\n",
    "# Function to generate confusion matrix and classification report\n",
    "def plot_confusion_matrix_and_report(generator, generator_name):\n",
    "    # Get predictions\n",
    "    predictions = model.predict(generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Get true labels\n",
    "    true_classes = generator.classes\n",
    "    class_labels = list(generator.class_indices.keys())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title(f'Confusion Matrix - {generator_name} Data')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.show()\n",
    "\n",
    "    # Print classification report\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "    print(f'Classification Report for {generator_name} Data:')\n",
    "    print(report)\n",
    "\n",
    "# Plot confusion matrix and classification report for train, val, and test data\n",
    "plot_confusion_matrix_and_report(train_generator, 'Training')\n",
    "plot_confusion_matrix_and_report(val_generator, 'Validation')\n",
    "plot_confusion_matrix_and_report(test_generator, 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeniorProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
