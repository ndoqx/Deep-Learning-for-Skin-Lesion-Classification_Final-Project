{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from itertools import cycle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SIZE = 128\n",
    "NUM_CLASSES = 7\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = r\"C:\\Users\\guita\\Desktop\\miniproject1\\HAM10000\\train\"\n",
    "val_dir = r\"C:\\Users\\guita\\Desktop\\miniproject1\\HAM10000\\val\"\n",
    "test_dir = r\"C:\\Users\\guita\\Desktop\\miniproject1\\HAM10000\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "def load_images_and_labels(image_dir, label_encoder):\n",
    "    image_paths = glob(os.path.join(image_dir, '*', '*.jpg'))\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for path in image_paths:\n",
    "        img = Image.open(path).resize((SIZE, SIZE))\n",
    "        images.append(np.asarray(img))\n",
    "        label = os.path.basename(os.path.dirname(path))\n",
    "        labels.append(label_encoder.transform([label])[0])\n",
    "    \n",
    "    images = np.array(images) / 255.0  # Normalize images\n",
    "    labels = to_categorical(labels, num_classes=NUM_CLASSES)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding to numeric values\n",
    "labels = sorted(os.listdir(train_dir))\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "# Load training, validation, and test data\n",
    "x_train, y_train = load_images_and_labels(train_dir, le)\n",
    "x_val, y_val = load_images_and_labels(val_dir, le)\n",
    "x_test, y_test = load_images_and_labels(test_dir, le)\n",
    "\n",
    "# Split training data into 5 subsets\n",
    "x_train_splits = np.array_split(x_train, 5)\n",
    "y_train_splits = np.array_split(y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = Sequential([\n",
    "    Conv2D(256, (3, 3), activation=\"relu\", input_shape=(SIZE, SIZE, 3)),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(32),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics callback for precision, recall, F1 score\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data\n",
    "        y_pred = self.model.predict(x_val)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "        val_loss = logs['val_loss']\n",
    "        val_accuracy = logs.get('val_accuracy', logs.get('val_acc'))  # Handle different versions\n",
    "\n",
    "        precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "        print(f'Epoch {epoch + 1} - '\n",
    "              f'Validation Loss: {val_loss:.4f}, '\n",
    "              f'Validation Accuracy: {val_accuracy:.4f}, '\n",
    "              f'Validation Error: {1 - val_accuracy:.4f}, '\n",
    "              f'Validation Precision: {precision:.4f}, '\n",
    "              f'Validation Recall: {recall:.4f}, '\n",
    "              f'Validation F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Metrics callback\n",
    "metrics_callback = MetricsCallback(validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on each subset sequentially\n",
    "for i in range(5):\n",
    "    print(f\"Training on subset {i+1}...\")\n",
    "    history = model.fit(\n",
    "        datagen.flow(x_train_splits[i], y_train_splits[i], batch_size=BATCH_SIZE),\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[early_stopping, metrics_callback],\n",
    "        verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_score = model.evaluate(x_val, y_val)\n",
    "print('Validation accuracy:', val_score[1])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_score[1])\n",
    "\n",
    "# Plot the training and validation accuracy and loss at each epoch\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training & Validation Loss\n",
    "axs[0, 0].plot(history.history['loss'], label='Train Loss')\n",
    "axs[0, 0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].set_title('Training & Validation Loss')\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "axs[0, 1].plot(history.history['acc'], label='Train Accuracy')\n",
    "axs[0, 1].plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].set_title('Training & Validation Accuracy')\n",
    "\n",
    "# Plot Validation Error\n",
    "axs[1, 0].plot(1 - np.array(history.history['val_acc']), label='Validation Error')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].set_title('Validation Error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on validation data\n",
    "y_val_pred = model.predict(x_val)\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for validation data\n",
    "cm_val = confusion_matrix(y_val_true, y_val_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Validation Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC-ROC curve for validation data\n",
    "y_val_true_binary = label_binarize(y_val_true, classes=np.unique(y_val_true))\n",
    "y_val_pred_binary = label_binarize(y_val_pred_classes, classes=np.unique(y_val_true))\n",
    "\n",
    "fpr_val = dict()\n",
    "tpr_val = dict()\n",
    "roc_auc_val = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr_val[i], tpr_val[i], _ = roc_curve(y_val_true_binary[:, i], y_val_pred_binary[:, i])\n",
    "    roc_auc_val[i] = roc_auc_score(y_val_true_binary[:, i], y_val_pred_binary[:, i])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(fpr_val[i], tpr_val[i], color=color, lw=2, label=f'Class {i} (AUC = {roc_auc_val[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Validation Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test data\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "y_test_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test data\n",
    "cm_test = confusion_matrix(y_test_true, y_test_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.show()\n",
    "\n",
    "# AUC-ROC curve for test data\n",
    "y_test_true_binary = label_binarize(y_test_true, classes=np.unique(y_test_true))\n",
    "y_test_pred_binary = label_binarize(y_test_pred_classes, classes=np.unique(y_test_true))\n",
    "\n",
    "fpr_test = dict()\n",
    "tpr_test = dict()\n",
    "roc_auc_test = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr_test[i], tpr_test[i], _ = roc_curve(y_test_true_binary[:, i], y_test_pred_binary[:, i])\n",
    "    roc_auc_test[i] = roc_auc_score(y_test_true_binary[:, i], y_test_pred_binary[:, i])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(fpr_test[i], tpr_test[i], color=color, lw=2, label=f'Class {i} (AUC = {roc_auc_test[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SeniorProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
