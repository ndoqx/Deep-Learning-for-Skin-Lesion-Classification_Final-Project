{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from itertools import cycle\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = r\"C:\\Users\\guita\\Desktop\\Senior project\\dataset\\HAM10000\\train\"\n",
    "val_dir = r\"C:\\Users\\guita\\Desktop\\Senior project\\dataset\\HAM10000\\val\"\n",
    "test_dir = r\"C:\\Users\\guita\\Desktop\\Senior project\\dataset\\HAM10000\\test\"\n",
    "\n",
    "# Constants\n",
    "SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = len(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample function to balance each class to 500 samples\n",
    "def resample_data(directory, target_count=500):\n",
    "    class_dirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    for class_dir in class_dirs:\n",
    "        class_path = os.path.join(directory, class_dir)\n",
    "        images = glob(os.path.join(class_path, \"*.jpg\"))\n",
    "        current_count = len(images)\n",
    "        if current_count < target_count:\n",
    "            # Augment the class to have `target_count` images\n",
    "            for i in range(target_count - current_count):\n",
    "                image = images[i % current_count]\n",
    "                image_name = os.path.basename(image)\n",
    "                new_image_name = f\"aug_{i}_{image_name}\"\n",
    "                new_image_path = os.path.join(class_path, new_image_name)\n",
    "                shutil.copy(image, new_image_path)\n",
    "        elif current_count > target_count:\n",
    "            # Reduce the class to `target_count` images\n",
    "            for image in images[target_count:]:\n",
    "                os.remove(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500 images belonging to 7 classes.\n",
      "Found 3500 images belonging to 7 classes.\n",
      "Found 1511 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Resample training data\n",
    "resample_data(train_dir)\n",
    "\n",
    "# Create ImageDataGenerator instances\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate data from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 126, 126, 256)     7168      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 63, 63, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 63, 63, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 61, 61, 128)       295040    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 30, 30, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                401440    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 777,671\n",
      "Trainable params: 777,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "model = Sequential([\n",
    "    Conv2D(256, (3, 3), activation=\"relu\", input_shape=(SIZE, SIZE, 3)),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(32),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics callback for precision, recall, F1 score\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, val_generator):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.val_generator = val_generator\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_true = self.val_generator.classes\n",
    "        y_pred = self.model.predict(self.val_generator)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "        val_loss = logs['val_loss']\n",
    "        val_accuracy = logs.get('val_accuracy', logs.get('val_acc'))  # Handle different versions\n",
    "\n",
    "        print(f'Epoch {epoch + 1} - '\n",
    "              f'Validation Loss: {val_loss:.4f}, '\n",
    "              f'Validation Accuracy: {val_accuracy:.4f}, '\n",
    "              f'Validation Precision: {precision:.4f}, '\n",
    "              f'Validation Recall: {recall:.4f}, '\n",
    "              f'Validation F1 Score: {f1_score:.4f}')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Metrics callback\n",
    "metrics_callback = MetricsCallback(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_2/conv2d_6/Relu' defined at (most recent call last):\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\guita\\AppData\\Local\\Temp\\ipykernel_1936\\942174314.py\", line 2, in <module>\n      history = model.fit(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_2/conv2d_6/Relu'\nOOM when allocating tensor with shape[128,256,126,126] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_2/conv2d_6/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3067]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/conv2d_6/Relu' defined at (most recent call last):\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\guita\\AppData\\Local\\Temp\\ipykernel_1936\\942174314.py\", line 2, in <module>\n      history = model.fit(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\guita\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_2/conv2d_6/Relu'\nOOM when allocating tensor with shape[128,256,126,126] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_2/conv2d_6/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3067]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, metrics_callback],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_score = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_score[1])\n",
    "\n",
    "# Plot the training and validation accuracy and loss at each epoch\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot Training & Validation Loss\n",
    "axs[0].plot(history.history['loss'], label='Train Loss')\n",
    "axs[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Training & Validation Loss')\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "axs[1].plot(history.history['acc'], label='Train Accuracy')\n",
    "axs[1].plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Training & Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for validation data\n",
    "y_val_true = val_generator.classes\n",
    "y_val_pred = model.predict(val_generator)\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "cm_val = confusion_matrix(y_val_true, y_val_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Validation Data')\n",
    "plt.show()\n",
    "\n",
    "# AUC-ROC curve for validation data\n",
    "y_val_true_binary = label_binarize(y_val_true, classes=np.unique(y_val_true))\n",
    "y_val_pred_binary = label_binarize(y_val_pred_classes, classes=np.unique(y_val_true))\n",
    "\n",
    "fpr_val = dict()\n",
    "tpr_val = dict()\n",
    "roc_auc_val = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr_val[i], tpr_val[i], _ = roc_curve(y_val_true_binary[:, i], y_val_pred_binary[:, i])\n",
    "    roc_auc_val[i] = roc_auc_score(y_val_true_binary[:, i], y_val_pred_binary[:, i])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(fpr_val[i], tpr_val[i], color=color, lw=2, label=f'Class {i} (AUC = {roc_auc_val[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Validation Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeniorProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
